# OmniData CLI

> ğŸ§  A forward-thinking, lightweight **universal data translator and inspector** written in Go.
> Work with heterogeneous structured data formats (CSV, JSON, XML, SQL, Excel, Parquet, Avro, and beyond) directly from the terminal.

[![CI](https://github.com/asearer/OmniData/actions/workflows/ci.yml/badge.svg)](https://github.com/asearer/OmniData/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/asearer/OmniData)](https://goreportcard.com/report/github.com/asearer/OmniData)
[![Go Version](https://img.shields.io/github/go-mod/go-version/asearer/OmniData)](go.mod)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## âœ¨ Features

* ğŸ”„ **Convert between formats**: CSV â†” JSON â†” XML â†” XLSX â†” SQL â†” Parquet â†” Avro
* ğŸ‘€ **Inspect data quickly**: `peek` command to view schema and top rows with statistics
* ğŸ“Š **Schema detection & stats**: Automatic type inference and column statistics
* ğŸ” **Schema diffing**: Compare schemas between two files with `diff` command
* ğŸ—„ï¸ **SQL support**: Query database tables directly and convert results to any supported format
* ğŸ“„ **Multiple output formats**: Export schema and diffs as Markdown, HTML, or JSON
* âš¡ **Streaming mode**: Process large files efficiently with `--stream` flag
* âš¡ **Fast & memory-efficient**: Stream large files using Goâ€™s native IO
* ğŸ“¦ **Portable**: single binary, no runtime dependencies
* ğŸ§© **Extensible architecture**: Add new formats or outputs with minimal code changes

---

## ğŸš€ Installation & Build

### Using Go

```bash
go install github.com/asearer/OmniData@latest
```

### Clone and Build

```bash
git clone https://github.com/asearer/OmniData.git
cd OmniData
go build -o omnidata
```

### Docker

```bash
docker build -t omnidata .
docker run --rm -v "$(pwd)":/data omnidata convert /data/input.csv /data/output.json
```

---

## ğŸ› ï¸ CI/CD

- Automated CI is powered by **GitHub Actions**! Each push or PR runs:
  - Full Go build/lint/test
  - Docker build (verifies Docker image compiles successfully)
- See the latest results and workflow run details above.

---

## ğŸ§° Usage

### Convert CSV â†’ JSON

```bash
./omnidata convert -i data.csv -o data.json --from csv --to json
```

### Convert JSON â†’ CSV

```bash
./omnidata convert -i data.json -o data.csv --from json --to csv
```

### Query SQL Database

```bash
./omnidata query -d "postgres://user:pass@localhost/db" -q "SELECT * FROM users" -o users.json --to json
```

### Using STDIN/STDOUT

```bash
cat data.csv | ./omnidata convert - - --from csv --to json > data.json
```

### Dry-Run Mode

```bash
./omnidata convert -i data.csv -o data.json --from csv --to json --dry-run
```

### Peek Command

```bash
./omnidata peek -i data.csv --format csv
./omnidata peek -i data.json --format json --rows 10 --stats
./omnidata peek -i data.csv --format csv --output-format markdown -o schema.md
```

### Diff Command

```bash
./omnidata diff -1 old.csv -2 new.csv --format1 csv --format2 csv
./omnidata diff -1 schema1.json -2 schema2.json --format1 json --format2 json --output-format html -o diff.html
```

### Streaming Mode

```bash
./omnidata convert -i large.csv -o large.json --from csv --to json --stream
```

---

## ğŸ“‚ Project Structure

```
OmniData/
â”œâ”€â”€ main.go
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ README.md
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ root.go
â”‚   â”œâ”€â”€ convert.go
â”‚   â”œâ”€â”€ diff.go
â”‚   â””â”€â”€ peek.go
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ convert/
â”‚   â”‚   â”œâ”€â”€ registry.go
â”‚   â”‚   â”œâ”€â”€ runner.go
â”‚   â”‚   â””â”€â”€ validator.go
â”‚   â”œâ”€â”€ formats/
â”‚   â”‚   â”œâ”€â”€ avro.go
â”‚   â”‚   â”œâ”€â”€ csv.go
â”‚   â”‚   â”œâ”€â”€ json.go
â”‚   â”‚   â”œâ”€â”€ parquet.go
â”‚   â”‚   â”œâ”€â”€ sql.go
â”‚   â”‚   â”œâ”€â”€ xlsx.go
â”‚   â”‚   â””â”€â”€ xml.go
â”‚   â”œâ”€â”€ inspect/
â”‚   â”‚   â”œâ”€â”€ diff.go
â”‚   â”‚   â”œâ”€â”€ peek.go
â”‚   â”‚   â””â”€â”€ schema.go
â”‚   â”œâ”€â”€ output/
â”‚   â”‚   â””â”€â”€ formatters.go
â”‚   â””â”€â”€ stream/
â”‚       â””â”€â”€ reader.go
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ convert/
â”‚   â”‚   â”œâ”€â”€ registry_test.go
â”‚   â”‚   â”œâ”€â”€ runner_test.go
â”‚   â”‚   â””â”€â”€ validator_test.go
â”‚   â””â”€â”€ formats/
â”‚       â”œâ”€â”€ csv_test.go
â”‚       â”œâ”€â”€ json_test.go
â”‚       â”œâ”€â”€ xlsx_test.go
â”‚       â””â”€â”€ xml_test.go
```

---

## ğŸ“‹ Supported Formats & Commands

| Format  | Convert | Peek | Diff | Query |
| ------- | :-----: | :--: | :--: | :---: |
| CSV     |    âœ…    |   âœ…  |   âœ…  |   âŒ   |
| JSON    |    âœ…    |   âœ…  |   âœ…  |   âŒ   |
| XML     |    âœ…    |   âœ…  |   âœ…  |   âŒ   |
| XLSX    |    âœ…    |   âœ…  |   âœ…  |   âŒ   |
| SQL     |    âœ…    |   âŒ  |   âŒ  |   âœ…   |
| Parquet |    âœ…    |   âœ…  |   âœ…  |   âŒ   |
| Avro    |    âœ…    |   âœ…  |   âœ…  |   âŒ   |

**Legend:** âœ… = supported, âŒ = not supported / not applicable

---

## âš™ï¸ Command vs Feature Matrix

| Command   | Input Formats                            | Output Formats                           | Flags & Options                                                                     | Notes                                                          |
| --------- | ---------------------------------------- | ---------------------------------------- | ----------------------------------------------------------------------------------- | -------------------------------------------------------------- |
| `convert` | CSV, JSON, XML, XLSX, SQL, Parquet, Avro | CSV, JSON, XML, XLSX, SQL, Parquet, Avro | `--from <format>` `--to <format>` `--stream` `--dry-run` `-i` `-o`                  | Supports streaming for large datasets; dry-run previews output |
| `peek`    | CSV, JSON, XML, XLSX, Parquet, Avro      | Markdown, HTML, JSON                     | `--rows <n>` `--stats` `--output-format <format>` `-i` `-o`                         | Preview schema + top rows; includes column stats               |
| `diff`    | CSV, JSON, XML, XLSX, Parquet, Avro      | Markdown, HTML, JSON                     | `-1` `-2` `--format1 <format>` `--format2 <format>` `--output-format <format>` `-o` | Compares schemas between two files                             |
| `query`   | SQL databases                            | CSV, JSON, XML, XLSX, Parquet, Avro      | `-d <db-connection>` `-q <query>` `--to <format>` `-o`                              | Execute SQL queries and convert results to supported formats   |

---

## ğŸ’¡ Why OmniData? (Real-World Use Cases)

OmniData is a universal CLI alternative to **jq**, **csvkit**, **xlsx2csv**, and other specialized tools:

* ğŸŒ **Universal** â†’ one CLI for multiple formats
* ğŸ§© **Interoperable** â†’ mix-and-match sources easily
* âš¡ **Efficient** â†’ Go-powered speed & memory efficiency
* ğŸ”® **Forward-thinking** â†’ supports SQL, XML, Excel, Parquet, Avro, and schema diffing

### Example Scenarios

* **Data Engineer** â†’ Convert CSV logs to JSON for ELK/Kafka pipelines
* **Developer** â†’ Convert API JSON responses into CSV or Excel
* **Analyst** â†’ Merge multiple file types into unified datasets
* **Ops** â†’ Automate conversions and database queries in CI/CD pipelines

---

## âš™ï¸ Architecture

OmniData is modular and extensible, built on Goâ€™s Cobra CLI framework.

```
cmd/       â†’ CLI commands (root, convert, query, inspect)
internal/  â†’ Core logic & converters
pkg/       â†’ Optional reusable modules
main.go    â†’ Program entrypoint
```

**Converter Interface Example:**

```go
type Converter interface {
    Read(input io.Reader) (DataSet, error)
    Write(output io.Writer, data DataSet) error
}
```

Adding new formats? Implement `Converter` and register in `registry`.

---

## ğŸ§ª Testing

Run tests:

```bash
go test ./... -v
```

---

## ğŸ“Œ Quick Reference CLI Examples


### Convert CSV â†’ JSON
----
```
./omnidata convert -i data.csv -o data.json --from csv --to json
```
### Convert JSON â†’ CSV
----
```
./omnidata convert -i data.json -o data.csv --from json --to csv
```
### Query SQL database
----
```
./omnidata query -d "postgres://user:pass@localhost/db" -q "SELECT * FROM users" -o users.json --to json
```
### Peek first 10 rows and stats
----
```
./omnidata peek -i data.csv --format csv --rows 10 --stats
```
### Compare schemas between two files
----
```
./omnidata diff -1 old.csv -2 new.csv --format1 csv --format2 csv --output-format html -o diff.html
```
### Streaming conversion for large files
----
```
./omnidata convert -i large.csv -o large.json --from csv --to json --stream
```

### Dry-run conversion
----
```
./omnidata convert -i data.csv -o data.json --from csv --to json --dry-run
```

---

ğŸ’¡ Tips & Best Practices

Use --stream for large files to avoid memory issues; works for CSV, JSON, Parquet, and Avro

Peek before converting to verify schema and data types using ./omnidata peek -i file

SQL queries: Use parameterized queries for large datasets and export directly to a supported format (--to csv/json/xlsx)

Schema diffing: Use diff to check changes before merging new datasets

Dry-run mode: Use --dry-run to preview conversions without writing output

Pipeline-friendly: OmniData works with STDIN/STDOUT, making it easy to chain commands in scripts